{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pretreatment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QQ8Pa8OagP5d"
      },
      "source": [
        "Всякие установки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aBS0RfzedyIf",
        "outputId": "3c5f4623-010f-40f9-df41-7b2cc9840a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dir_path = '/content/drive/My Drive/автобрея/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fGOTfNH3fclX",
        "outputId": "c2b87edf-994b-4dc7-bc94-1e171095a8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 8.0MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vqcExLyrg_93",
        "colab": {}
      },
      "source": [
        "import ast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PVMZn8qchCJ0",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCabZDYCkA1a",
        "colab": {}
      },
      "source": [
        "import gensim, logging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kEYZ25i_fZJe",
        "outputId": "571d13ab-c346-4273-d230-5e7f3c9110a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from pymystem3 import Mystem\n",
        "import re\n",
        "\n",
        "morph = MorphAnalyzer()\n",
        "token = RegexpTokenizer('\\w+')\n",
        "stops = set(stopwords.words('russian'))\n",
        "\n",
        "def normalize_pm(text):\n",
        "    words = [morph.parse(word)[0].normal_form for word in tokenize(text) if word]\n",
        "    return words\n",
        "\n",
        "def tokenize(text):\n",
        "    return token.tokenize(text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LDp5WLtWgOVh",
        "outputId": "cf934475-8b57-46c4-898f-8e9543cb31b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "!pip install git+https://github.com/lopuhin/python-adagram.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/lopuhin/python-adagram.git\n",
            "  Cloning https://github.com/lopuhin/python-adagram.git to /tmp/pip-req-build-9qo6w9uu\n",
            "  Running command git clone -q https://github.com/lopuhin/python-adagram.git /tmp/pip-req-build-9qo6w9uu\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from adagram==0.0.1) (0.29.14)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from adagram==0.0.1) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.6/dist-packages (from adagram==0.0.1) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adagram==0.0.1) (1.12.0)\n",
            "Building wheels for collected packages: adagram\n",
            "  Building wheel for adagram (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adagram: filename=adagram-0.0.1-cp36-cp36m-linux_x86_64.whl size=464599 sha256=3e2babbc61c4e2ebd100843906392d25173830536c562aabda45bbeba9ced142\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1jg9ox7k/wheels/11/0f/46/f5df96670df8f7973b4c2311ffc9b02e435a7bd3207f992c4d\n",
            "Successfully built adagram\n",
            "Installing collected packages: adagram\n",
            "Successfully installed adagram-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S6MHadV2gTlQ",
        "outputId": "ae04b325-cba2-4edc-e5c5-9f2186b14fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib -d adagram.joblib"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG output created by Wget 1.19.4 on linux-gnu.\n",
            "\n",
            "Reading HSTS entries from /root/.wget-hsts\n",
            "URI encoding = ‘UTF-8’\n",
            "Converted file name 'all.a010.p10.d300.w5.m100.nonorm.slim.joblib' (UTF-8) -> 'all.a010.p10.d300.w5.m100.nonorm.slim.joblib' (UTF-8)\n",
            "--2019-12-24 14:03:55--  https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.25.61\n",
            "Caching s3.amazonaws.com => 52.216.25.61\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.25.61|:443... connected.\n",
            "Created socket 5.\n",
            "Releasing 0x0000556c1d33ca60 (new refcount 1).\n",
            "Initiating SSL handshake.\n",
            "Handshake successful; connected socket 5 to SSL handle 0x0000556c1d360000\n",
            "certificate:\n",
            "  subject: CN=s3.amazonaws.com,O=Amazon.com\\\\, Inc.,L=Seattle,ST=Washington,C=US\n",
            "  issuer:  CN=DigiCert Baltimore CA-2 G2,OU=www.digicert.com,O=DigiCert Inc,C=US\n",
            "X509 certificate successfully verified and matches host s3.amazonaws.com\n",
            "\n",
            "---request begin---\n",
            "GET /kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib HTTP/1.1\r\n",
            "User-Agent: Wget/1.19.4 (linux-gnu)\r\n",
            "Accept: */*\r\n",
            "Accept-Encoding: identity\r\n",
            "Host: s3.amazonaws.com\r\n",
            "Connection: Keep-Alive\r\n",
            "\r\n",
            "---request end---\n",
            "HTTP request sent, awaiting response... \n",
            "---response begin---\n",
            "HTTP/1.1 200 OK\r\n",
            "x-amz-id-2: wKyyNvkfua/Zm4eevBWCJEl277L6nU719IhzcLCw4EPoWTghN3kAIPrW2/fx/yYJmHymJDymRIg=\r\n",
            "x-amz-request-id: 3A8E2B2E57477D29\r\n",
            "Date: Tue, 24 Dec 2019 14:03:56 GMT\r\n",
            "Last-Modified: Mon, 30 Oct 2017 18:17:18 GMT\r\n",
            "ETag: \"f5f49c3c6ebb8e0578161cad1a6ab2d1-88\"\r\n",
            "Accept-Ranges: bytes\r\n",
            "Content-Type: application/x-www-form-urlencoded; charset=utf-8\r\n",
            "Content-Length: 1462416741\r\n",
            "Server: AmazonS3\r\n",
            "\r\n",
            "---response end---\n",
            "200 OK\n",
            "Registered socket 5 for persistent reuse.\n",
            "URI content encoding = ‘utf-8’\n",
            "Length: 1462416741 (1.4G) [application/x-www-form-urlencoded]\n",
            "Saving to: ‘all.a010.p10.d300.w5.m100.nonorm.slim.joblib’\n",
            "\n",
            "all.a010.p10.d300.w 100%[===================>]   1.36G  66.3MB/s    in 17s     \n",
            "\n",
            "2019-12-24 14:04:13 (79.7 MB/s) - ‘all.a010.p10.d300.w5.m100.nonorm.slim.joblib’ saved [1462416741/1462416741]\n",
            "\n",
            "URI encoding = ‘UTF-8’\n",
            "Converted file name 'index.html' (UTF-8) -> 'index.html' (UTF-8)\n",
            "--2019-12-24 14:04:13--  http://adagram.joblib/\n",
            "Resolving adagram.joblib (adagram.joblib)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘adagram.joblib’\n",
            "FINISHED --2019-12-24 14:04:13--\n",
            "Total wall clock time: 18s\n",
            "Downloaded: 1 files, 1.4G in 17s (79.7 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2_3EFm4egWl9",
        "colab": {}
      },
      "source": [
        "import adagram\n",
        "vm = adagram.VectorModel.load('all.a010.p10.d300.w5.m100.nonorm.slim.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vpyw8fI5glY_"
      },
      "source": [
        "Установки кончились!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wqBzQploRuWb",
        "colab": {}
      },
      "source": [
        "## преобразуем food_seed в тот же вид, что имеют нами добавленные сиды\n",
        "food_file = dir_path + 'Food_word.txt'\n",
        "with open(food_file, 'r', encoding = 'utf-8') as f:\n",
        "  food_seed = f.readlines()\n",
        "food_seed = [line.split('        ') for line in food_seed]\n",
        "food_seed = [[line[1], line[2].strip('\\n')] for line in food_seed]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7b7CSdSdelAh",
        "outputId": "6faed5c3-b346-4da7-bbfd-9a669bc7fa46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "food_seed"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['вкусный', '1'],\n",
              " ['большой', '1'],\n",
              " ['прекрасный', '1'],\n",
              " ['разнообразный', '1'],\n",
              " ['единственный', '1'],\n",
              " ['достойный', '1'],\n",
              " ['странный', '1'],\n",
              " ['отличный', '1'],\n",
              " ['горячий', '1'],\n",
              " ['сытный', '1'],\n",
              " ['свежий', '1'],\n",
              " ['великолепный', '1'],\n",
              " ['интересный', '1'],\n",
              " ['различный', '1'],\n",
              " ['необычный', '1'],\n",
              " ['приятный', '1'],\n",
              " ['плохой', '0'],\n",
              " ['невкусный', '0'],\n",
              " ['посредственно', '0'],\n",
              " ['понравиться', '1']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-AXw4gJkeG77",
        "colab": {}
      },
      "source": [
        "## преобразуем service_seed в тот же вид, что имеют нами добавленные сиды\n",
        "service_file = dir_path + 'Service_word.txt'\n",
        "with open(service_file, 'r', encoding = 'utf-8') as f:\n",
        "  service_seed = f.readlines()\n",
        "service_seed = [line.split('\\t') for line in service_seed]\n",
        "service_seed = [[line[1], line[2].strip('\\n')] for line in service_seed]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OlTwXgsxd-CI",
        "outputId": "ce078637-9dd6-43e0-8e03-959eff50b50f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "service_seed"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['приветливый', '1'],\n",
              " ['внимательный', '1'],\n",
              " ['приятный', '1'],\n",
              " ['вежливый', '1'],\n",
              " ['хороший', '1'],\n",
              " ['ненавязчивый', '1'],\n",
              " ['доброжелательный', '1'],\n",
              " ['дружелюбный', '1'],\n",
              " ['хамоватый', '0'],\n",
              " ['отличный', '1'],\n",
              " ['милый', '1'],\n",
              " ['гостеприимный', '1'],\n",
              " ['качественный', '1'],\n",
              " ['отзывчивый', '1'],\n",
              " ['радушный', '1'],\n",
              " ['красивый', '1'],\n",
              " ['душевный', '1'],\n",
              " ['веселый', '1'],\n",
              " ['понравиться', '1'],\n",
              " ['спасибо', '1']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xPu5Ah__fTdr",
        "colab": {}
      },
      "source": [
        "## открываем наши добавочные фудосиды\n",
        "with open('/content/drive/My Drive/автобрея/food_adagram_done.txt', 'r', encoding = 'utf-8') as f:\n",
        "  food_adagram = f.readlines()\n",
        "food_adagram = [x.strip('\\n').split('\\t') for x in food_adagram]\n",
        "\n",
        "with open('/content/drive/My Drive/автобрея/food_wordnet_done.txt', 'r', encoding = 'utf-8') as f:\n",
        "  food_wordnet = f.readlines()\n",
        "food_wordnet = [x.strip('\\n').split('\\t') for x in food_wordnet]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wzv_7vn5g2-8",
        "colab": {}
      },
      "source": [
        "## открываем наши добавочные сервисосиды\n",
        "with open('/content/drive/My Drive/автобрея/service_adagram_done.txt', 'r', encoding = 'utf-8') as f:\n",
        "  service_adagram = f.readlines()\n",
        "service_adagram = [x.strip('\\n').split('\\t') for x in service_adagram]\n",
        "\n",
        "with open('/content/drive/My Drive/автобрея/service_wordnet_done.txt', 'r', encoding = 'utf-8') as f:\n",
        "  service_wordnet = f.readlines()\n",
        "service_wordnet = [x.strip('\\n').split('\\t') for x in service_wordnet]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kj8Q5KnNg9t0",
        "outputId": "5fdb6293-b85c-4568-cd6c-600fb1c4c3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## объединяем изначальные сиды еды с нашими (!после превращения изначальных в тот же вид почистилось сильнее. Было 174 - стало 156)\n",
        "food_dirty = food_adagram + food_wordnet + food_seed\n",
        "food = set([str(line) for line in food_dirty])\n",
        "food = [ast.literal_eval(x) for x in food]\n",
        "len(food)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9d0D594phIEu",
        "outputId": "440b5765-6ea7-4a98-b391-db3f21699b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## то же для сервисных сидов\n",
        "service_dirty = service_adagram + service_wordnet + service_seed\n",
        "service = set([str(line) for line in service_dirty])\n",
        "service = [ast.literal_eval(x) for x in service]\n",
        "len(service)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "248"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERaaC5RfOJwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## сохраняем полученные сиды еды и сервиса в отдельные файлы с помощью pickle\n",
        "with open(\"/content/drive/My Drive/автобрея/Food_final_seeds.pickle\", \"wb\") as f:\n",
        "    pickle.dump(food, f)\n",
        "\n",
        "with open(\"/content/drive/My Drive/автобрея/Service_final_seeds.pickle\", \"wb\") as f:\n",
        "    pickle.dump(service, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TWy3CnhOheYc",
        "colab": {}
      },
      "source": [
        "##  а также сохраняем в отдельные файлы tsv\n",
        "with open(\"/content/drive/My Drive/автобрея/Food_final_seeds.tsv\", \"w\") as f:\n",
        "    for i in food:\n",
        "      s = 'Food\\t'+i[0]+'\\t'+i[1]+'\\n'\n",
        "      f.write(s)\n",
        "\n",
        "with open(\"/content/drive/My Drive/автобрея/Service_final_seeds.tsv\", \"w\") as f:\n",
        "    for i in service:\n",
        "      s = 'Service'+'\\t'+i[0]+'\\t'+i[1]+'\\n'\n",
        "      f.write(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kMpoNmLujn9n"
      },
      "source": [
        "Далее сохраняем векторы:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FJDevKxxiHEQ",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/автобрея/topics.txt', 'r', encoding = 'utf-8') as t:\n",
        "  topics = t.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gf5EtkAkj6CJ",
        "colab": {}
      },
      "source": [
        "food_topic = re.findall(r'\"(\\w+)\"', topics[0])\n",
        "service_topic = re.findall(r'\"(\\w+)\"', topics[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I2HOjgqmj8ux",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xWfLkk9MkEGL",
        "outputId": "fb9f73d1-fbda-4942-dfbc-c50fb10a138b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "amodel = gensim.models.KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/автобрея/model.bin\", binary=True)\n",
        "amodel.init_sims(replace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-23 16:21:29,922 : INFO : loading projection weights from /content/drive/My Drive/автобрея/model.bin\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2019-12-23 16:21:36,258 : INFO : loaded (248978, 300) matrix from /content/drive/My Drive/автобрея/model.bin\n",
            "2019-12-23 16:21:36,259 : INFO : precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l6LjK31zkFm6",
        "colab": {}
      },
      "source": [
        "#словарь тэгов для конвертации из формата pymorphy в w2v\n",
        "tags = { 'INFN':'VERB', 'NOUN':'NOUN', 'ADJF':'ADJ', 'ADJS':'ADJ','PREP':'ADP', 'ADVB':'ADV', 'CONJ':'SCONJ', 'PRCL':'PART', 'NUMR':'NUM', 'NPRO':'PRON', 'INTJ':'INTJ', 'PRED':'ADV', 'VERB':'VERB', 'GRND':'GRND', None:'None', 'PRTF':'PRTF', 'PRTS':'PRTS'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XUTf74bHkJcD",
        "colab": {}
      },
      "source": [
        "def convert_word(word):                 #в модели вордувек слова хранятся так: дом_NOUN - эта функция преобразует слово в такой формат\n",
        "    aword = re.sub('ё', \"е\", word)\n",
        "    p = morph.parse(word)[0]\n",
        "    tag = tags[p.tag.POS]\n",
        "    new_word = aword+'_'+tag\n",
        "    return new_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wk6-pYAmkK8G",
        "colab": {}
      },
      "source": [
        "food_topic_vectors = [amodel.wv[convert_word(topic_word)] for topic_word in food_topic]            #вектор для топика фуд\n",
        "food_topic_vector = sum(food_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AoPfc5ZJkNsC",
        "colab": {}
      },
      "source": [
        "## сохраняем вектор топиков еды в пикл файл\n",
        "with open(\"/content/drive/My Drive/автобрея/Food_topic_vector.pickle\", \"wb\") as f:\n",
        "    pickle.dump(food_topic_vector, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ba3lsb2IklSd",
        "colab": {}
      },
      "source": [
        "service_topic_vectors = [amodel.wv[convert_word(topic_word)] for topic_word in service_topic]             #  вектор для топика сервис\n",
        "service_topic_vector = sum(service_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "04TivQqCkwVh",
        "colab": {}
      },
      "source": [
        "## сохраняем вектор сервисных топиков в пикл файл\n",
        "with open(\"/content/drive/My Drive/автобрея/Service_topic_vector.pickle\", \"wb\") as f:\n",
        "    pickle.dump(service_topic_vector, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QoXLnEXumQYU",
        "colab": {}
      },
      "source": [
        "## Может, еще стоит сделать и сохранить отдельно вектора для сидов...? пока хз"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uyWtlzTtlKNo"
      },
      "source": [
        "Теперь позитивные/негативные вектора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v1Mw1CTIlEg2",
        "colab": {}
      },
      "source": [
        "positive = []                                   #собрать все позит и негат слова\n",
        "negative = [] \n",
        "\n",
        "for j in [food_wordnet, food_adagram, service_wordnet, service_adagram]:\n",
        "  for i in j:\n",
        "    if i[1] == '1':\n",
        "      positive.append(i[0])\n",
        "    else:\n",
        "      negative.append(i[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1BneeljilRZ5",
        "colab": {}
      },
      "source": [
        "neg_vectors = [amodel.wv[convert_word(n_word)] for n_word in negative if convert_word(n_word) in amodel.wv.vocab]             #  вектор негативных слов\n",
        "neg_vector = sum(neg_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4IeDI87plTHo",
        "colab": {}
      },
      "source": [
        "pos_vectors = [amodel.wv[convert_word(p_word)] for p_word in positive if convert_word(p_word) in amodel.wv.vocab]                #вектор позит слов\n",
        "pos_vector = sum(pos_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5EpX1P0TlgsY",
        "colab": {}
      },
      "source": [
        "## сохраняем их в пиклы\n",
        "with open(\"/content/drive/My Drive/автобрея/Positive_vector.pickle\", \"wb\") as f:\n",
        "    pickle.dump(pos_vector, f)\n",
        "\n",
        "with open(\"/content/drive/My Drive/автобрея/Negative_vector.pickle\", \"wb\") as f:\n",
        "    pickle.dump(neg_vector, f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}