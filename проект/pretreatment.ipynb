{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQ8Pa8OagP5d"
   },
   "source": [
    "Всякие установки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBS0RfzedyIf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "dir_path = '/content/drive/My Drive/автобрея/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGOTfNH3fclX"
   },
   "outputs": [],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqcExLyrg_93"
   },
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVMZn8qchCJ0"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCabZDYCkA1a"
   },
   "outputs": [],
   "source": [
    "import gensim, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kEYZ25i_fZJe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "token = RegexpTokenizer('\\w+')\n",
    "stops = set(stopwords.words('russian'))\n",
    "\n",
    "def normalize_pm(text):\n",
    "    words = [morph.parse(word)[0].normal_form for word in tokenize(text) if word]\n",
    "    return words\n",
    "\n",
    "def tokenize(text):\n",
    "    return token.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDp5WLtWgOVh"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/lopuhin/python-adagram.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6MHadV2gTlQ"
   },
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib -d adagram.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_3EFm4egWl9"
   },
   "outputs": [],
   "source": [
    "import adagram\n",
    "vm = adagram.VectorModel.load('all.a010.p10.d300.w5.m100.nonorm.slim.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vpyw8fI5glY_"
   },
   "source": [
    "Установки кончились!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqBzQploRuWb"
   },
   "outputs": [],
   "source": [
    "## преобразуем food_seed в тот же вид, что имеют нами добавленные сиды\n",
    "food_file = dir_path + 'Food_word.txt'\n",
    "with open(food_file, 'r', encoding = 'utf-8') as f:\n",
    "  food_seed = f.readlines()\n",
    "food_seed = [line.split('        ') for line in food_seed]\n",
    "food_seed = [[line[1], line[2].strip('\\n')] for line in food_seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "7b7CSdSdelAh",
    "outputId": "4760479c-7eb1-4c59-85a7-6bfbe3131577"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['вкусный', '1'],\n",
       " ['большой', '1'],\n",
       " ['прекрасный', '1'],\n",
       " ['разнообразный', '1'],\n",
       " ['единственный', '1'],\n",
       " ['достойный', '1'],\n",
       " ['странный', '1'],\n",
       " ['отличный', '1'],\n",
       " ['горячий', '1'],\n",
       " ['сытный', '1'],\n",
       " ['свежий', '1'],\n",
       " ['великолепный', '1'],\n",
       " ['интересный', '1'],\n",
       " ['различный', '1'],\n",
       " ['необычный', '1'],\n",
       " ['приятный', '1'],\n",
       " ['плохой', '0'],\n",
       " ['невкусный', '0'],\n",
       " ['посредственно', '0'],\n",
       " ['понравиться', '1']]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AXw4gJkeG77"
   },
   "outputs": [],
   "source": [
    "## преобразуем service_seed в тот же вид, что имеют нами добавленные сиды\n",
    "service_file = dir_path + 'Service_word.txt'\n",
    "with open(service_file, 'r', encoding = 'utf-8') as f:\n",
    "  service_seed = f.readlines()\n",
    "service_seed = [line.split('\\t') for line in service_seed]\n",
    "service_seed = [[line[1], line[2].strip('\\n')] for line in service_seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "OlTwXgsxd-CI",
    "outputId": "ea69f4cb-6be2-4590-b2d4-e9b584a2d79d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['приветливый', '1'],\n",
       " ['внимательный', '1'],\n",
       " ['приятный', '1'],\n",
       " ['вежливый', '1'],\n",
       " ['хороший', '1'],\n",
       " ['ненавязчивый', '1'],\n",
       " ['доброжелательный', '1'],\n",
       " ['дружелюбный', '1'],\n",
       " ['хамоватый', '0'],\n",
       " ['отличный', '1'],\n",
       " ['милый', '1'],\n",
       " ['гостеприимный', '1'],\n",
       " ['качественный', '1'],\n",
       " ['отзывчивый', '1'],\n",
       " ['радушный', '1'],\n",
       " ['красивый', '1'],\n",
       " ['душевный', '1'],\n",
       " ['веселый', '1'],\n",
       " ['понравиться', '1'],\n",
       " ['спасибо', '1']]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPu5Ah__fTdr"
   },
   "outputs": [],
   "source": [
    "## открываем наши добавочные фудосиды\n",
    "with open('/content/drive/My Drive/автобрея/food_adagram_done.txt', 'r', encoding = 'utf-8') as f:\n",
    "  food_adagram = f.readlines()\n",
    "food_adagram = [x.strip('\\n').split('\\t') for x in food_adagram]\n",
    "\n",
    "with open('/content/drive/My Drive/автобрея/food_wordnet_done.txt', 'r', encoding = 'utf-8') as f:\n",
    "  food_wordnet = f.readlines()\n",
    "food_wordnet = [x.strip('\\n').split('\\t') for x in food_wordnet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wzv_7vn5g2-8"
   },
   "outputs": [],
   "source": [
    "## открываем наши добавочные сервисосиды\n",
    "with open('/content/drive/My Drive/автобрея/service_adagram_done.txt', 'r', encoding = 'utf-8') as f:\n",
    "  service_adagram = f.readlines()\n",
    "service_adagram = [x.strip('\\n').split('\\t') for x in service_adagram]\n",
    "\n",
    "with open('/content/drive/My Drive/автобрея/service_wordnet_done.txt', 'r', encoding = 'utf-8') as f:\n",
    "  service_wordnet = f.readlines()\n",
    "service_wordnet = [x.strip('\\n').split('\\t') for x in service_wordnet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kj8Q5KnNg9t0",
    "outputId": "4a3533ba-79b1-41f1-bb9d-64ebb9b8362c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## объединяем изначальные сиды еды с нашими (!после превращения изначальных в тот же вид почистилось сильнее. Было 174 - стало 156)\n",
    "food_dirty = food_adagram + food_wordnet + food_seed\n",
    "food = set([str(line) for line in food_dirty])\n",
    "food = [ast.literal_eval(x) for x in food]\n",
    "len(food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9d0D594phIEu",
    "outputId": "21b39d7a-e870-4794-cef6-9aa8b23cd5ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## то же для сервисных сидов\n",
    "service_dirty = service_adagram + service_wordnet + service_seed\n",
    "service = set([str(line) for line in service_dirty])\n",
    "service = [ast.literal_eval(x) for x in service]\n",
    "len(service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWy3CnhOheYc"
   },
   "outputs": [],
   "source": [
    "## сохраняем полученные сиды еды и сервиса в отдельные файлы с помощью pickle\n",
    "with open(\"/content/drive/My Drive/автобрея/Food_final_seeds.pickle\", \"wb\") as f:\n",
    "    pickle.dump(food, f)\n",
    "\n",
    "with open(\"/content/drive/My Drive/автобрея/Service_final_seeds.pickle\", \"wb\") as f:\n",
    "    pickle.dump(service, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kMpoNmLujn9n"
   },
   "source": [
    "Теперь все сиды мы можем просто брать из файлов пикл.\n",
    "\n",
    "Далее сохраняем векторы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJDevKxxiHEQ"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/автобрея/topics.txt', 'r', encoding = 'utf-8') as t:\n",
    "  topics = t.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gf5EtkAkj6CJ"
   },
   "outputs": [],
   "source": [
    "food_topic = re.findall(r'\"(\\w+)\"', topics[0])\n",
    "service_topic = re.findall(r'\"(\\w+)\"', topics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2HOjgqmj8ux"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "xWfLkk9MkEGL",
    "outputId": "fb9f73d1-fbda-4942-dfbc-c50fb10a138b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-23 16:21:29,922 : INFO : loading projection weights from /content/drive/My Drive/автобрея/model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2019-12-23 16:21:36,258 : INFO : loaded (248978, 300) matrix from /content/drive/My Drive/автобрея/model.bin\n",
      "2019-12-23 16:21:36,259 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "amodel = gensim.models.KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/автобрея/model.bin\", binary=True)\n",
    "amodel.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l6LjK31zkFm6"
   },
   "outputs": [],
   "source": [
    "#словарь тэгов для конвертации из формата pymorphy в w2v\n",
    "tags = { 'INFN':'VERB', 'NOUN':'NOUN', 'ADJF':'ADJ', 'ADJS':'ADJ','PREP':'ADP', 'ADVB':'ADV', 'CONJ':'SCONJ', 'PRCL':'PART', 'NUMR':'NUM', 'NPRO':'PRON', 'INTJ':'INTJ', 'PRED':'ADV', 'VERB':'VERB', 'GRND':'GRND', None:'None', 'PRTF':'PRTF', 'PRTS':'PRTS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUTf74bHkJcD"
   },
   "outputs": [],
   "source": [
    "def convert_word(word):                 #в модели вордувек слова хранятся так: дом_NOUN - эта функция преобразует слово в такой формат\n",
    "    aword = re.sub('ё', \"е\", word)\n",
    "    p = morph.parse(word)[0]\n",
    "    tag = tags[p.tag.POS]\n",
    "    new_word = aword+'_'+tag\n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wk6-pYAmkK8G"
   },
   "outputs": [],
   "source": [
    "food_topic_vectors = [amodel.wv[convert_word(topic_word)] for topic_word in food_topic]            #вектор для топика фуд\n",
    "food_topic_vector = sum(food_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoPfc5ZJkNsC"
   },
   "outputs": [],
   "source": [
    "## сохраняем вектор топиков еды в пикл файл\n",
    "with open(\"/content/drive/My Drive/автобрея/Food_topic_vector.pickle\", \"wb\") as f:\n",
    "    pickle.dump(food_topic_vector, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ba3lsb2IklSd"
   },
   "outputs": [],
   "source": [
    "service_topic_vectors = [amodel.wv[convert_word(topic_word)] for topic_word in service_topic]             #  вектор для топика сервис\n",
    "service_topic_vector = sum(service_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04TivQqCkwVh"
   },
   "outputs": [],
   "source": [
    "## сохраняем вектор сервисных топиков в пикл файл\n",
    "with open(\"/content/drive/My Drive/автобрея/Service_topic_vector.pickle\", \"wb\") as f:\n",
    "    pickle.dump(service_topic_vector, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QoXLnEXumQYU"
   },
   "outputs": [],
   "source": [
    "## Может, еще стоит сделать и сохранить отдельно вектора для сидов...? пока хз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyWtlzTtlKNo"
   },
   "source": [
    "Теперь позитивные/негативные вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1Mw1CTIlEg2"
   },
   "outputs": [],
   "source": [
    "positive = []                                   #собрать все позит и негат слова\n",
    "negative = [] \n",
    "\n",
    "for j in [food_wordnet, food_adagram, service_wordnet, service_adagram]:\n",
    "  for i in j:\n",
    "    if i[1] == '1':\n",
    "      positive.append(i[0])\n",
    "    else:\n",
    "      negative.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BneeljilRZ5"
   },
   "outputs": [],
   "source": [
    "neg_vectors = [amodel.wv[convert_word(n_word)] for n_word in negative if convert_word(n_word) in amodel.wv.vocab]             #  вектор негативных слов\n",
    "neg_vector = sum(neg_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4IeDI87plTHo"
   },
   "outputs": [],
   "source": [
    "pos_vectors = [amodel.wv[convert_word(p_word)] for p_word in positive if convert_word(p_word) in amodel.wv.vocab]                #вектор позит слов\n",
    "pos_vector = sum(pos_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5EpX1P0TlgsY"
   },
   "outputs": [],
   "source": [
    "## сохраняем их в пиклы\n",
    "with open(\"/content/drive/My Drive/автобрея/Positive_vector.pickle\", \"wb\") as f:\n",
    "    pickle.dump(pos_vector, f)\n",
    "\n",
    "with open(\"/content/drive/My Drive/автобрея/Negative_vector.pickle\", \"wb\") as f:\n",
    "    pickle.dump(neg_vector, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pretreatment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
