{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsC2ab7Fn0W3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88f6b2ca-e1d3-44d7-f27f-371acaa235d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dir_path = '/content/drive/My Drive/автобрея/проект/'"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5pX6yNjufkS",
        "colab_type": "text"
      },
      "source": [
        "Необходимые библиотеки и т.д."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Ikwsgtn4_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "19d230c4-c218-471a-cb10-933e227c2fe5"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████                         | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW1dd5iLn5HM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDpARs3Qn5J3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2a14836b-e7aa-4d53-ba67-5ee289c95915"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from pymystem3 import Mystem\n",
        "import re\n",
        "\n",
        "morph = MorphAnalyzer()\n",
        "token = RegexpTokenizer('\\w+')\n",
        "stops = set(stopwords.words('russian'))\n",
        "\n",
        "def normalize_pm(text):\n",
        "    words = [morph.parse(word)[0].normal_form for word in tokenize(text) if word]\n",
        "    return words\n",
        "\n",
        "def tokenize(text):\n",
        "    return token.tokenize(text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwKt7w8An5Mg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "7c85a8db-5dc8-41a6-829c-4e5ab5af3f3d"
      },
      "source": [
        "!pip install git+https://github.com/lopuhin/python-adagram.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/lopuhin/python-adagram.git\n",
            "  Cloning https://github.com/lopuhin/python-adagram.git to /tmp/pip-req-build-cl_fsm0w\n",
            "  Running command git clone -q https://github.com/lopuhin/python-adagram.git /tmp/pip-req-build-cl_fsm0w\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from adagram==0.0.1) (0.29.14)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from adagram==0.0.1) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.6/dist-packages (from adagram==0.0.1) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adagram==0.0.1) (1.12.0)\n",
            "Building wheels for collected packages: adagram\n",
            "  Building wheel for adagram (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adagram: filename=adagram-0.0.1-cp36-cp36m-linux_x86_64.whl size=464610 sha256=a4f19fc3f4beac5704c3e98ab391e21d2fef3fb85bd4d1912d2a6ef4307a1579\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-el8b31jc/wheels/11/0f/46/f5df96670df8f7973b4c2311ffc9b02e435a7bd3207f992c4d\n",
            "Successfully built adagram\n",
            "Installing collected packages: adagram\n",
            "Successfully installed adagram-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB3bJGX5oJQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d691e703-1672-4ff8-d1ae-7fdbf54d0b17"
      },
      "source": [
        "!wget https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib -d adagram.joblib"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG output created by Wget 1.19.4 on linux-gnu.\n",
            "\n",
            "Reading HSTS entries from /root/.wget-hsts\n",
            "URI encoding = ‘UTF-8’\n",
            "Converted file name 'all.a010.p10.d300.w5.m100.nonorm.slim.joblib' (UTF-8) -> 'all.a010.p10.d300.w5.m100.nonorm.slim.joblib' (UTF-8)\n",
            "--2019-12-24 12:01:11--  https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.140.94\n",
            "Caching s3.amazonaws.com => 52.216.140.94\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.140.94|:443... connected.\n",
            "Created socket 5.\n",
            "Releasing 0x000056538e168a60 (new refcount 1).\n",
            "Initiating SSL handshake.\n",
            "Handshake successful; connected socket 5 to SSL handle 0x000056538e18c000\n",
            "certificate:\n",
            "  subject: CN=s3.amazonaws.com,O=Amazon.com\\\\, Inc.,L=Seattle,ST=Washington,C=US\n",
            "  issuer:  CN=DigiCert Baltimore CA-2 G2,OU=www.digicert.com,O=DigiCert Inc,C=US\n",
            "X509 certificate successfully verified and matches host s3.amazonaws.com\n",
            "\n",
            "---request begin---\n",
            "GET /kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib HTTP/1.1\r\n",
            "User-Agent: Wget/1.19.4 (linux-gnu)\r\n",
            "Accept: */*\r\n",
            "Accept-Encoding: identity\r\n",
            "Host: s3.amazonaws.com\r\n",
            "Connection: Keep-Alive\r\n",
            "\r\n",
            "---request end---\n",
            "HTTP request sent, awaiting response... \n",
            "---response begin---\n",
            "HTTP/1.1 200 OK\r\n",
            "x-amz-id-2: dbefbOUJkv4UgK5TquFkhiAH0yDC++ZDT6oKO5llYMcD9AZZ6qZMmqNG7QwUNQNCqAkSJaTwOkI=\r\n",
            "x-amz-request-id: FF1BCCFF03F3DC3D\r\n",
            "Date: Tue, 24 Dec 2019 12:01:12 GMT\r\n",
            "Last-Modified: Mon, 30 Oct 2017 18:17:18 GMT\r\n",
            "ETag: \"f5f49c3c6ebb8e0578161cad1a6ab2d1-88\"\r\n",
            "Accept-Ranges: bytes\r\n",
            "Content-Type: application/x-www-form-urlencoded; charset=utf-8\r\n",
            "Content-Length: 1462416741\r\n",
            "Server: AmazonS3\r\n",
            "\r\n",
            "---response end---\n",
            "200 OK\n",
            "Registered socket 5 for persistent reuse.\n",
            "URI content encoding = ‘utf-8’\n",
            "Length: 1462416741 (1.4G) [application/x-www-form-urlencoded]\n",
            "Saving to: ‘all.a010.p10.d300.w5.m100.nonorm.slim.joblib’\n",
            "\n",
            "all.a010.p10.d300.w 100%[===================>]   1.36G  84.2MB/s    in 16s     \n",
            "\n",
            "2019-12-24 12:01:27 (85.1 MB/s) - ‘all.a010.p10.d300.w5.m100.nonorm.slim.joblib’ saved [1462416741/1462416741]\n",
            "\n",
            "URI encoding = ‘UTF-8’\n",
            "Converted file name 'index.html' (UTF-8) -> 'index.html' (UTF-8)\n",
            "--2019-12-24 12:01:27--  http://adagram.joblib/\n",
            "Resolving adagram.joblib (adagram.joblib)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘adagram.joblib’\n",
            "FINISHED --2019-12-24 12:01:27--\n",
            "Total wall clock time: 17s\n",
            "Downloaded: 1 files, 1.4G in 16s (85.1 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU_SFMCwoJUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import adagram\n",
        "vm = adagram.VectorModel.load('all.a010.p10.d300.w5.m100.nonorm.slim.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnPy0E_yoJS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import spatial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGOIwCFBs6C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim, logging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPHIIiD9s6qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I_v6b3ws730",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "14193b6b-388b-4e18-e2c0-13f1ae2c9d6d"
      },
      "source": [
        "amodel = gensim.models.KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/автобрея/проект/model.bin\", binary=True)\n",
        "amodel.init_sims(replace=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-24 12:01:55,075 : INFO : loading projection weights from /content/drive/My Drive/автобрея/проект/model.bin\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2019-12-24 12:02:01,251 : INFO : loaded (248978, 300) matrix from /content/drive/My Drive/автобрея/проект/model.bin\n",
            "2019-12-24 12:02:01,252 : INFO : precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx3aN8BhoYyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## достаем наши сиды и сохраняем в переменные\n",
        "#### надо будет все это отредачить до просто пикл файла когда будем грузить все на гит (и в другом ноутбуке тоже)\n",
        "with open(\"/content/drive/My Drive/автобрея/Food_final_seeds.tsv\", \"r\") as c: \n",
        "  f_seeds = c.readlines()\n",
        "\n",
        "with open(\"/content/drive/My Drive/автобрея/Service_final_seeds.tsv\", \"r\") as c:\n",
        "  s_seeds = c.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyyKPqLfzRWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "food_seeds = []\n",
        "for i in f_seeds:\n",
        "  seed = i.split('\\t')\n",
        "  food_seeds.append([seed[1], int(seed[2].strip('\\n'))])\n",
        "\n",
        "service_seeds = []\n",
        "for i in s_seeds:\n",
        "  seed = i.split('\\t')\n",
        "  service_seeds.append([seed[1], int(seed[2].strip('\\n'))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh3Wvigd3ViD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afc7b4fc-58ca-4fce-b71d-f2db1d866948"
      },
      "source": [
        "food_seeds"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['любоваться', 1],\n",
              " ['качественный', 1],\n",
              " ['впечатлить', 1],\n",
              " ['некачественный', 0],\n",
              " ['блестящий', 1],\n",
              " ['сытный', 1],\n",
              " ['чудесный', 1],\n",
              " ['неплохой', 1],\n",
              " ['распрекрасный', 1],\n",
              " ['миловидный', 1],\n",
              " ['занятный', 1],\n",
              " ['классный', 1],\n",
              " ['зловещий', 0],\n",
              " ['аппетитный', 1],\n",
              " ['славный', 1],\n",
              " ['порадовать', 1],\n",
              " ['настоящий', 1],\n",
              " ['фантастический', 1],\n",
              " ['интерестный', 1],\n",
              " ['отменный', 1],\n",
              " ['скверный', 0],\n",
              " ['недурно', 1],\n",
              " ['импонировать', 1],\n",
              " ['поразительный', 1],\n",
              " ['прикольный', 1],\n",
              " ['невиданный', 1],\n",
              " ['хорошенький', 1],\n",
              " ['эксклюзивный', 1],\n",
              " ['первоклассный', 1],\n",
              " ['странный', 1],\n",
              " ['посредственно', 0],\n",
              " ['интересный', 1],\n",
              " ['невкусно', 0],\n",
              " ['вкусный', 1],\n",
              " ['роскошный', 1],\n",
              " ['причудливый', 1],\n",
              " ['своеобразный', 0],\n",
              " ['правильный', 1],\n",
              " ['освежать', 1],\n",
              " ['сегодняшний', 1],\n",
              " ['яркий', 1],\n",
              " ['дурной', 0],\n",
              " ['вкусно', 1],\n",
              " ['потрясающий', 1],\n",
              " ['единственный', 1],\n",
              " ['бархатистый', 1],\n",
              " ['приличный', 1],\n",
              " ['столовский', 0],\n",
              " ['неповторимый', 1],\n",
              " ['сочный', 1],\n",
              " ['великолепный', 1],\n",
              " ['феерический', 1],\n",
              " ['привлекательный', 1],\n",
              " ['непонятный', 0],\n",
              " ['свежий', 1],\n",
              " ['жуткий', 0],\n",
              " ['ужасный', 0],\n",
              " ['приторный', 0],\n",
              " ['неясный', 0],\n",
              " ['пересолить', 0],\n",
              " ['особенный', 1],\n",
              " ['нравиться', 1],\n",
              " ['изумительный', 1],\n",
              " ['пахучий', 0],\n",
              " ['несъедобный', 0],\n",
              " ['симпатичный', 1],\n",
              " ['незабываемый', 1],\n",
              " ['небанальный', 1],\n",
              " ['рекомендовать', 1],\n",
              " ['всевозможный', 1],\n",
              " ['горячий', 1],\n",
              " ['нехороший', 0],\n",
              " ['отличный', 1],\n",
              " ['нежный', 1],\n",
              " ['хороший', 1],\n",
              " ['любить', 1],\n",
              " ['нелепый', 0],\n",
              " ['великолепно', 1],\n",
              " ['невкусный', 0],\n",
              " ['сладкий', 1],\n",
              " ['ароматный', 1],\n",
              " ['удачный', 1],\n",
              " ['отвратительный', 0],\n",
              " ['удивлять', 1],\n",
              " ['необыкновенный', 1],\n",
              " ['нормально', 1],\n",
              " ['достойный', 1],\n",
              " ['душистый', 1],\n",
              " ['прекрасный', 1],\n",
              " ['непревзойденный', 1],\n",
              " ['бесподобный', 1],\n",
              " ['безвкусный', 0],\n",
              " ['различный', 1],\n",
              " ['показательный', 1],\n",
              " ['несравненный', 1],\n",
              " ['замечательный', 1],\n",
              " ['превосходный', 1],\n",
              " ['приглянуться', 1],\n",
              " ['пресный', 0],\n",
              " ['красивый', 1],\n",
              " ['восхитительный', 1],\n",
              " ['разноплановый', 1],\n",
              " ['нехороший', 1],\n",
              " ['уникальный', 1],\n",
              " ['бодрящий', 1],\n",
              " ['любопытный', 1],\n",
              " ['неудовлетворительный', 0],\n",
              " ['пышный', 1],\n",
              " ['разнообразный', 1],\n",
              " ['необычайный', 1],\n",
              " ['неподражаемый', 1],\n",
              " ['большой', 1],\n",
              " ['прохладный', 1],\n",
              " ['адекватный', 1],\n",
              " ['забавный', 1],\n",
              " ['страшный', 0],\n",
              " ['многообразный', 1],\n",
              " ['необъяснимый', 1],\n",
              " ['оригинальный', 1],\n",
              " ['пленительный', 1],\n",
              " ['увлекательный', 1],\n",
              " ['чудной', 1],\n",
              " ['слабый', 0],\n",
              " ['плохой', 0],\n",
              " ['гениальный', 1],\n",
              " ['средне', 0],\n",
              " ['небывалый', 1],\n",
              " ['смехотворный', 0],\n",
              " ['добротный', 1],\n",
              " ['обольстительный', 1],\n",
              " ['выдающийся', 1],\n",
              " ['диковинный', 1],\n",
              " ['странно', 0],\n",
              " ['понравиться', 1],\n",
              " ['посредственный', 0],\n",
              " ['особый', 1],\n",
              " ['необычный', 1],\n",
              " ['насыщенный', 1],\n",
              " ['неприятный', 0],\n",
              " ['впечатлиться', 1],\n",
              " ['замечательно', 1],\n",
              " ['занимательный', 1],\n",
              " ['смутный', 0],\n",
              " ['неординарный', 1],\n",
              " ['расстраивать', 0],\n",
              " ['прелестный', 1],\n",
              " ['чудный', 1],\n",
              " ['исключительный', 1],\n",
              " ['приятный', 1],\n",
              " ['идеально', 1],\n",
              " ['пригожий', 1],\n",
              " ['спертый', 0],\n",
              " ['незаурядный', 1],\n",
              " ['одобрять', 1],\n",
              " ['удивительный', 1],\n",
              " ['недостойный', 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQCeuiPeqgaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Достаем вектора топиков\n",
        "with open(\"/content/drive/My Drive/автобрея/проект/Service_topic_vector.pickle\", \"rb\") as c:\n",
        "  service_topic_vector = pickle.load(c)\n",
        "\n",
        "with open(\"/content/drive/My Drive/автобрея/проект/Food_topic_vector.pickle\", \"rb\") as c:\n",
        "  food_topic_vector = pickle.load(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyDmXKxaq1Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## достаем векторы негативных и позитивных тональных слов\n",
        "with open(\"/content/drive/My Drive/автобрея/проект/Positive_vector.pickle\", \"rb\") as c:\n",
        "  pos_vector = pickle.load(c)\n",
        "\n",
        "with open(\"/content/drive/My Drive/автобрея/проект/Negative_vector.pickle\", \"rb\") as c:\n",
        "  neg_vector = pickle.load(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNWNsQxcpxCZ",
        "colab_type": "text"
      },
      "source": [
        "Классификатор:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJDvsDsVsyEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#словарь тэгов для конвертации из формата pymorphy в w2v\n",
        "tags = { 'INFN':'VERB', 'NOUN':'NOUN', 'ADJF':'ADJ', 'ADJS':'ADJ','PREP':'ADP', 'ADVB':'ADV', 'CONJ':'SCONJ', 'PRCL':'PART', 'NUMR':'NUM', 'NPRO':'PRON', 'INTJ':'INTJ', 'PRED':'ADV', 'VERB':'VERB', 'GRND':'GRND', None:'None', 'PRTF':'PRTF', 'PRTS':'PRTS'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9UHlWiPsy2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_word(word):                 #в модели вордувек слова хранятся так: дом_NOUN - эта функция преобразует слово в такой формат\n",
        "    aword = re.sub('ё', \"е\", word)\n",
        "    p = morph.parse(word)[0]\n",
        "    tag = tags[p.tag.POS]\n",
        "    new_word = aword+'_'+tag\n",
        "    return new_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS7IiVs5qfsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_topics(file, service_vector, food_vector):\n",
        "  food_class_r = {}                             \n",
        "  service_class_r = {}\n",
        "\n",
        "  with open(file, 'r', encoding = 'utf-8') as f:\n",
        "    text = f.read()\n",
        "    sents = re.split('(?<=[.!?]) (?=[A-ЯЁA-Z])', text)\n",
        "\n",
        "    for sent in sents:\n",
        "      for word in sent.split():\n",
        "        norm = ' '.join(normalize_pm(word))\n",
        "        if norm not in stops and convert_word(norm) in amodel.wv.vocab:\n",
        "\n",
        "          word_vector = amodel.wv[convert_word(norm)]\n",
        "          sim_service = spatial.distance.cosine(word_vector, service_vector)\n",
        "          sim_food = spatial.distance.cosine(word_vector, food_vector)\n",
        "\n",
        "          if sim_service<sim_food:\n",
        "            service_class_r[(norm, sim_service)] = sents.index(sent)\n",
        "          elif sim_service>sim_food:\n",
        "            food_class_r[(norm, sim_food)] = sents.index(sent)\n",
        "  return sents, food_class_r, service_class_r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QECag-qyT7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier1(file, result = set()): ## потом объединяем его со вторым\n",
        "  with open(file, 'r', encoding = 'utf-8') as f:\n",
        "    text = f.read()\n",
        "    sents = re.split('(?<=[.!?]) (?=[A-ЯЁA-Z])', text)\n",
        "    \n",
        "  for sent in sents:\n",
        "    try:\n",
        "      sent_words = [normalize_pm(w.strip())[0] for w in sent.split()]\n",
        "    except:\n",
        "      print('Cannot handle sentence ' + str(sents.index(sent) + 1))\n",
        "    ## ищем все тональное о еде:\n",
        "    for line in food_seeds:\n",
        "      t_word = normalize_pm(line[0].strip())[0]\n",
        "      tone = bool(int(line[1])) # так удобно их преобразовывать, если встр. \"не\"\n",
        "      if t_word in sent_words:\n",
        "        #id_sent = sents.index(sent) + 1 # прибавляем 1, т.к. в юдпайпе счет с одного\n",
        "        i = sent_words.index(t_word)\n",
        "        try:\n",
        "          if sent_words[i-1] == 'не':\n",
        "            tone_words = sent_words[i-1] + ' ' + sent_words[i]\n",
        "            #id_tone = str(i) + ',' + str(i+1) # плюс один по тем же причинам\n",
        "            tone = int(not tone)\n",
        "          elif sent_words[i-2] == 'не':\n",
        "            tone_words = sent_words[i-2] + ' ' + sent_words[i-1] + ' ' + sent_words[i]\n",
        "            #id_tone = str(i-1) + ',' + str(i) + ',' + str(i+1) # тоже\n",
        "            tone = int(not tone)\n",
        "          else:\n",
        "            tone_words = sent_words[i]\n",
        "            #id_tone = str(i+1) # тож\n",
        "            tone = int(tone)\n",
        "        except IndexError:\n",
        "          tone_words = sent_words[i]\n",
        "          tone = int(tone)\n",
        "        current = 'Food\\t' + str(tone) + '\\t' + tone_words\n",
        "        result.add(current)\n",
        "    ## ищем все тональное о сервисе:\n",
        "    for line in service_seeds:\n",
        "      t_word = normalize_pm(line[0].strip())[0]\n",
        "      tone = bool(int(line[1])) # так удобно их преобразовывать, если встр. \"не\"\n",
        "      if t_word in sent_words:\n",
        "        #id_sent = sents.index(sent) + 1 # прибавляем 1, т.к. в юдпайпе счет с одного\n",
        "        i = sent_words.index(t_word)\n",
        "        try:\n",
        "          if sent_words[i-1] == 'не':\n",
        "            tone_words = sent_words[i-1] + ' ' + sent_words[i]\n",
        "            #id_tone = str(i) + ',' + str(i+1) # плюс один по тем же причинам\n",
        "            tone = int(not tone)\n",
        "          elif sent_words[i-2] == 'не':\n",
        "            tone_words = sent_words[i-2] + ' ' + sent_words[i-1] + ' ' + sent_words[i]\n",
        "            #id_tone = str(i-1) + ',' + str(i) + ',' + str(i+1) # тоже\n",
        "            tone = int(not tone)\n",
        "          else:\n",
        "            tone_words = sent_words[i]\n",
        "            #id_tone = str(i+1) # тож\n",
        "            tone = int(tone)\n",
        "        except IndexError:\n",
        "          tone_words = sent_words[i]\n",
        "          tone = int(tone)\n",
        "        current = 'Service\\t' + str(tone) + '\\t' + tone_words\n",
        "        result.add(current)\n",
        "  return(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7fXF_g6S6r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vect_sim(word, vector1, vector2):\n",
        "  sim1 = spatial.distance.cosine(amodel.wv[convert_word(word)], vector1)\n",
        "  sim2 = spatial.distance.cosine(amodel.wv[convert_word(word)], vector2)\n",
        "  return sim1, sim2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPkrsL-AuSDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier2(file, result = set()): \n",
        "  \"\"\"\n",
        "  Можно вместо пустого резалта давать ему резалт из другого классифаера и они будут объединяться\n",
        "  Например, можно будет сделать так:\n",
        "  Сверху у нас уже есть simple_result первого классификатора на тексте 6668\n",
        "  Можно запустить классификатор два на этом результате\n",
        "  result = classifier2(file, result = simple_result)\n",
        "  Тогда классификатор2 будет добавлять свои штучки в то же множество, и данные не будут повторяться\n",
        "\n",
        "  И вообще потом эти функции можно запускать на куче текстов друг за другом\n",
        "  \"\"\"\n",
        "  sents, food_class_r, service_class_r = get_topics(file, service_topic_vector, food_topic_vector)\n",
        "\n",
        "  for obj in food_class_r:\n",
        "    id_sent = food_class_r[obj]\n",
        "    sent = re.sub ('- ', '', sents[id_sent])\n",
        "    sent_words = [normalize_pm(w.strip())[0] for w in sent.split()]\n",
        "    asp_label = 'Food'\n",
        "    word = obj[0]\n",
        "    p = morph.parse(word)[0]\n",
        "    pos = p.tag.POS\n",
        "    id_word = sent_words.index(word)\n",
        "\n",
        "    if pos == 'ADVB':\n",
        "      sim_pos, sim_neg = vect_sim(word, pos_vector, neg_vector)\n",
        "      if sim_pos < sim_neg:\n",
        "        label = 1\n",
        "      else: \n",
        "        label = 0\n",
        "      current = str(asp_label) + '\\t' + str(label) + '\\t' + word\n",
        "      result.add(current)\n",
        "      \n",
        "    elif pos == 'ADJF':\n",
        "      try:\n",
        "        target_noun1 = sent_words[id_word+1]\n",
        "        p = morph.parse(target_noun1)[0]\n",
        "        pos1 = p.tag.POS \n",
        "      except IndexError:\n",
        "        pass\n",
        "      try:\n",
        "        target_noun2 = sent_words[id_word-2]\n",
        "        p = morph.parse(target_noun2)[0]\n",
        "        pos2 = p.tag.POS\n",
        "      except IndexError:\n",
        "        pass\n",
        "\n",
        "      if pos1 and pos1 == 'NOUN':\n",
        "        sim_service, sim_food = vect_sim(target_noun1, service_topic_vector, food_topic_vector)\n",
        "        if sim_service < 0.5 or sim_food < 0.5: #не берем совсем неблизкие к фуд и сервис штуки\n",
        "          if sim_service < sim_food:\n",
        "            asp_label = 'Service'\n",
        "          else:\n",
        "            asp_label = 'Food'\n",
        "        else:\n",
        "          asp_label = None\n",
        "        sim_pos, sim_neg = vect_sim(word, pos_vector, neg_vector)\n",
        "        if sim_pos < sim_neg:\n",
        "          label = 1\n",
        "        else: \n",
        "          label = 0\n",
        "      elif pos2 and pos2 == 'NOUN':\n",
        "        sim_service, sim_food = vect_sim(target_noun2, service_topic_vector, food_topic_vector)\n",
        "        if sim_service < 0.5 or sim_food < 0.5: #не берем совсем неблизкие к фуд и сервис штуки\n",
        "          if sim_service < sim_food:\n",
        "            asp_label = 'Service'\n",
        "          else:\n",
        "            asp_label = 'Food'\n",
        "        else:\n",
        "          asp_label = None\n",
        "        sim_pos, sim_neg = vect_sim(word, pos_vector, neg_vector)\n",
        "        if sim_pos < sim_neg:\n",
        "          label = 1\n",
        "        else: \n",
        "          label = 0\n",
        "      else:\n",
        "        label = None\n",
        "        asp_label = None\n",
        "      if abs(sim_pos - sim_neg) < 0.02:\n",
        "        label = None \n",
        "\n",
        "      current = str(asp_label) + '\\t' + str(label) + '\\t' + word\n",
        "      result.add(current)\n",
        "      #print(current, word)\n",
        "    \n",
        "    if pos == 'NOUN':\n",
        "      #adj = None\n",
        "      pos1 = None\n",
        "      pos2 = None\n",
        "      try:\n",
        "        target_adj1 = sent_words[id_word-1]\n",
        "        p = morph.parse(target_adj1)[0]\n",
        "        pos1 = p.tag.POS\n",
        "        \n",
        "      except IndexError:\n",
        "        pass\n",
        "      try:\n",
        "        target_adj2 = sent_words[id_word+2]\n",
        "        p = morph.parse(target_adj2)[0]\n",
        "        pos2 = p.tag.POS\n",
        "      except IndexError:\n",
        "        pass\n",
        "      if pos1 and pos1 == 'ADJF':\n",
        "        adj = target_adj1\n",
        "        sim_pos, sim_neg = vect_sim(adj, pos_vector, neg_vector)\n",
        "        if sim_pos < sim_neg:\n",
        "          label = 1\n",
        "        else: \n",
        "          label = 0\n",
        "        if sent_words[sent_words.index(adj)-1] == 'не':\n",
        "          if label == 1:\n",
        "            label == 0\n",
        "          elif label == 0:\n",
        "            label = 1\n",
        "          tone_words = 'не ' + adj\n",
        "          #id_word = str(sent_words.index(adj)) + ',' + str(sent_words.index(adj) + 1) #тк в юдпайпе не с нуля\n",
        "        else:\n",
        "          tone_words = adj\n",
        "          #id_word = str(sent_words.index(adj) + 1)\n",
        "\n",
        "      elif pos2 and pos2 == 'ADJF':\n",
        "        adj = target_adj2\n",
        "        sim_pos, sim_neg = vect_sim(adj, pos_vector, neg_vector)\n",
        "        if sim_pos < sim_neg:\n",
        "          label = 1\n",
        "        else: \n",
        "          label = 0\n",
        "        if sent_words[sent_words.index(adj)-1] == 'не':\n",
        "          if label == 1:\n",
        "            label == 0\n",
        "          elif label == 0:\n",
        "            label = 1\n",
        "          tone_words = 'не ' + adj\n",
        "          #id_word = str(sent_words.index(adj)) + ',' + str(sent_words.index(adj) + 1) #тк в юдпайпе не с нуля\n",
        "        else: \n",
        "          tone_words = adj\n",
        "          #id_word = str(sent_words.index(adj) + 1)\n",
        "\n",
        "      else:\n",
        "        label = None\n",
        "        tone_words = None\n",
        "      if abs(sim_pos - sim_neg) < 0.02:\n",
        "        label = None \n",
        "      current = str(asp_label) + '\\t' + str(label) + '\\t' + str(tone_words)\n",
        "      result.add(current)\n",
        "      #print(current, word)\n",
        "\n",
        "  final_result = set()\n",
        "  for i in result:\n",
        "    if \"None\" not in i:\n",
        "      final_result.add(i)\n",
        "\n",
        "  return final_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3UAMiRzEACw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# вот эту функцию можно применять на любом тексте и получать тональный словарь текста в переменной и файлом\n",
        "def final_classifier(file, result = set()):\n",
        "  middle_result = classifier1(file, result)\n",
        "  final_result = classifier2(file, middle_result)\n",
        "\n",
        "  new_file = file.split('.')[0] + '_done.txt'\n",
        "  with open(new_file, 'a', encoding = 'utf-8') as w:\n",
        "    for i in final_result:\n",
        "      w.write(i + '\\n')\n",
        "  return final_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhZBLwcLbdnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for file in files:\n",
        "#  final_classifier(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB0TT28MbNwz",
        "colab_type": "text"
      },
      "source": [
        "Ниже просто всякие проверки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3PW8U0esXgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_file = '/content/drive/My Drive/автобрея/проект/6668.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zkie31Ar6Dx0",
        "colab_type": "code",
        "outputId": "636fe9c7-05db-4fa3-d927-048fdfeea6d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "simple_result = classifier1(test_file)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cannot handle sentence 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96QD8HG5-1IF",
        "colab_type": "code",
        "outputId": "9ed02866-e481-4141-9d70-9f55f37dedb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "simple_result"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Food\\t0\\tплохой',\n",
              " 'Food\\t1\\tбольшой',\n",
              " 'Food\\t1\\tвкусно',\n",
              " 'Food\\t1\\tвкусный',\n",
              " 'Food\\t1\\tзамечательный',\n",
              " 'Food\\t1\\tнеплохой',\n",
              " 'Food\\t1\\tпонравиться',\n",
              " 'Food\\t1\\tприятный',\n",
              " 'Food\\t1\\tсытный',\n",
              " 'Food\\t1\\tхороший',\n",
              " 'Service\\t0\\tплохой',\n",
              " 'Service\\t1\\tзамечательный',\n",
              " 'Service\\t1\\tнедорогой',\n",
              " 'Service\\t1\\tнеплохой',\n",
              " 'Service\\t1\\tпонравиться',\n",
              " 'Service\\t1\\tприятный',\n",
              " 'Service\\t1\\tрадушно',\n",
              " 'Service\\t1\\tспасибо',\n",
              " 'Service\\t1\\tхороший'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbuiGSDsPnIX",
        "colab_type": "code",
        "outputId": "242858d5-54a0-4b37-ebea-642292e09a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "classifier2(test_file)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Food\\t0\\tпоздний',\n",
              " 'Food\\t1\\tвкусно',\n",
              " 'Food\\t1\\tне огромный',\n",
              " 'Food\\t1\\tсытный'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd5RGQ8XT1HT",
        "colab_type": "code",
        "outputId": "ffdd50c2-7546-4139-a79d-97e8d606d3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "result_6668 = classifier2(test_file, simple_result)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR2DSvjTEc5U",
        "colab_type": "code",
        "outputId": "71d17dc9-eab8-4e38-cee2-d89351a395e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "result_6668"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Food\\t0\\tплохой',\n",
              " 'Food\\t0\\tпоздний',\n",
              " 'Food\\t1\\tбольшой',\n",
              " 'Food\\t1\\tвкусно',\n",
              " 'Food\\t1\\tвкусный',\n",
              " 'Food\\t1\\tзамечательный',\n",
              " 'Food\\t1\\tне огромный',\n",
              " 'Food\\t1\\tнеплохой',\n",
              " 'Food\\t1\\tпонравиться',\n",
              " 'Food\\t1\\tприятный',\n",
              " 'Food\\t1\\tсытный',\n",
              " 'Food\\t1\\tхороший',\n",
              " 'Service\\t0\\tплохой',\n",
              " 'Service\\t1\\tзамечательный',\n",
              " 'Service\\t1\\tнедорогой',\n",
              " 'Service\\t1\\tнеплохой',\n",
              " 'Service\\t1\\tпонравиться',\n",
              " 'Service\\t1\\tприятный',\n",
              " 'Service\\t1\\tрадушно',\n",
              " 'Service\\t1\\tспасибо',\n",
              " 'Service\\t1\\tхороший'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ2F2ct7EUHE",
        "colab_type": "code",
        "outputId": "38fd00e3-ab1b-4738-f02e-5d0474e7b588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(result_6668)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxNL29aTFLpP",
        "colab_type": "code",
        "outputId": "b0c6d7fd-6468-41c5-f748-3e0d73098d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "result_6668_2 = final_classifier(test_file)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cannot handle sentence 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWZocu_4FXys",
        "colab_type": "code",
        "outputId": "d98939f3-b067-4d21-f80f-535f6b3c093f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(result_6668_2)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly2OZYKy38E7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}