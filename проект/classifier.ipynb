{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier first and the last.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsC2ab7Fn0W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dir_path = '/content/drive/My Drive/автобрея/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5pX6yNjufkS",
        "colab_type": "text"
      },
      "source": [
        "Необходимые библиотеки и т.д."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Ikwsgtn4_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW1dd5iLn5HM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDpARs3Qn5J3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from pymystem3 import Mystem\n",
        "import re\n",
        "\n",
        "morph = MorphAnalyzer()\n",
        "token = RegexpTokenizer('\\w+')\n",
        "stops = set(stopwords.words('russian'))\n",
        "\n",
        "def normalize_pm(text):\n",
        "    words = [morph.parse(word)[0].normal_form for word in tokenize(text) if word]\n",
        "    return words\n",
        "\n",
        "def tokenize(text):\n",
        "    return token.tokenize(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwKt7w8An5Mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+https://github.com/lopuhin/python-adagram.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB3bJGX5oJQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib -d adagram.joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU_SFMCwoJUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import adagram\n",
        "vm = adagram.VectorModel.load('all.a010.p10.d300.w5.m100.nonorm.slim.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnPy0E_yoJS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import spatial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGOIwCFBs6C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim, logging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPHIIiD9s6qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I_v6b3ws730",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amodel = gensim.models.KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/автобрея/model.bin\", binary=True)\n",
        "amodel.init_sims(replace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx3aN8BhoYyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## достаем наши сиды и сохраняем в переменные (все эти данные сохранены в файлах pickle)\n",
        "with open(\"/content/drive/My Drive/автобрея/Food_final_seeds.pickle\", \"rb\") as c: \n",
        "  food_seeds = pickle.load(c)\n",
        "\n",
        "with open(\"/content/drive/My Drive/автобрея/Service_final_seeds.pickle\", \"rb\") as c:\n",
        "  service_seeds = pickle.load(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQCeuiPeqgaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Достаем вектора топиков\n",
        "with open(\"/content/drive/My Drive/автобрея/Service_topic_vector.pickle\", \"rb\") as c:\n",
        "  service_topic_vector = pickle.load(c)\n",
        "\n",
        "with open(\"/content/drive/My Drive/автобрея/Food_topic_vector.pickle\", \"rb\") as c:\n",
        "  food_topic_vector = pickle.load(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyDmXKxaq1Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## достаем векторы негативных и позитивных тональных слов\n",
        "with open(\"/content/drive/My Drive/автобрея/Positive_vector.pickle\", \"rb\") as c:\n",
        "  pos_vector = pickle.load(c)\n",
        "\n",
        "with open(\"/content/drive/My Drive/автобрея/Negative_vector.pickle\", \"rb\") as c:\n",
        "  neg_vector = pickle.load(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNWNsQxcpxCZ",
        "colab_type": "text"
      },
      "source": [
        "Классификатор:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJDvsDsVsyEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#словарь тэгов для конвертации из формата pymorphy в w2v\n",
        "tags = { 'INFN':'VERB', 'NOUN':'NOUN', 'ADJF':'ADJ', 'ADJS':'ADJ','PREP':'ADP', 'ADVB':'ADV', 'CONJ':'SCONJ', 'PRCL':'PART', 'NUMR':'NUM', 'NPRO':'PRON', 'INTJ':'INTJ', 'PRED':'ADV', 'VERB':'VERB', 'GRND':'GRND', None:'None', 'PRTF':'PRTF', 'PRTS':'PRTS'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9UHlWiPsy2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_word(word):                 #в модели вордувек слова хранятся так: дом_NOUN - эта функция преобразует слово в такой формат\n",
        "    aword = re.sub('ё', \"е\", word)\n",
        "    p = morph.parse(word)[0]\n",
        "    tag = tags[p.tag.POS]\n",
        "    new_word = aword+'_'+tag\n",
        "    return new_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS7IiVs5qfsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_topics(file, service_vector, food_vector):\n",
        "  food_class_r = {}                             \n",
        "  service_class_r = {}\n",
        "\n",
        "  with open(file, 'r', encoding = 'utf-8') as f:\n",
        "    text = f.read()\n",
        "    sents = re.split('(?<=[.!?]) (?=[A-ЯЁA-Z])', text)\n",
        "\n",
        "    for sent in sents:\n",
        "      for word in sent.split():\n",
        "        norm = ' '.join(normalize_pm(word))\n",
        "        if norm not in stops and convert_word(norm) in amodel.wv.vocab:\n",
        "\n",
        "          word_vector = amodel.wv[convert_word(norm)]\n",
        "          sim_service = spatial.distance.cosine(word_vector, service_vector)\n",
        "          sim_food = spatial.distance.cosine(word_vector, food_vector)\n",
        "\n",
        "          if sim_service<sim_food:\n",
        "            service_class_r[(norm, sim_service)] = sents.index(sent)\n",
        "          elif sim_service>sim_food:\n",
        "            food_class_r[(norm, sim_food)] = sents.index(sent)\n",
        "  return sents, food_class_r, service_class_r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QECag-qyT7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier1(file, result = set()): ## можно вместо пустого резалта давать ему резалт из другого классифаера и они будут объединяться\n",
        "  with open(file, 'r', encoding = 'utf-8') as f:\n",
        "    text = f.read()\n",
        "    sents = re.split('(?<=[.!?]) (?=[A-ЯЁA-Z])', text)\n",
        "    \n",
        "  for sent in sents:\n",
        "    try:\n",
        "      sent_words = [normalize_pm(w.strip())[0] for w in sent.split()]\n",
        "    except:\n",
        "      print('Cannot handle sentence ' + str(sents.index(sent) + 1))\n",
        "    ## ищем все тональное о еде:\n",
        "    for line in food_seeds:\n",
        "      t_word = normalize_pm(line[0].strip())[0]\n",
        "      tone = bool(int(line[1])) # так удобно их преобразовывать, если встр. \"не\"\n",
        "      if t_word in sent_words:\n",
        "        id_sent = sents.index(sent) + 1 # прибавляем 1, т.к. в юдпайпе счет с одного\n",
        "        i = sent_words.index(t_word)\n",
        "        try:\n",
        "          if sent_words[i-1] == 'не':\n",
        "            id_tone = str(i) + ',' + str(i+1) # плюс один по тем же причинам\n",
        "            tone = int(not tone)\n",
        "          elif sent_words[i-2] == 'не':\n",
        "            id_tone = str(i-1) + ',' + str(i) + ',' + str(i+1) # тоже\n",
        "            tone = int(not tone)\n",
        "          else:\n",
        "            id_tone = str(i+1) # тож\n",
        "            tone = int(tone)\n",
        "        except IndexError:\n",
        "          pass\n",
        "        current = str(id_sent) + '\\t' + id_tone + '\\t' + 'Food\\t' + str(tone)\n",
        "        result.add(current)\n",
        "    ## ищем все тональное о сервисе:\n",
        "    for line in service_seeds:\n",
        "      t_word = normalize_pm(line[0].strip())[0]\n",
        "      tone = bool(int(line[1])) # так удобно их преобразовывать, если встр. \"не\"\n",
        "      if t_word in sent_words:\n",
        "        id_sent = sents.index(sent) + 1 # прибавляем 1, т.к. в юдпайпе счет с одного\n",
        "        i = sent_words.index(t_word)\n",
        "        try:\n",
        "          if sent_words[i-1] == 'не':\n",
        "            id_tone = str(i) + ',' + str(i+1) # плюс один по тем же причинам\n",
        "            tone = int(not tone)\n",
        "          elif sent_words[i-2] == 'не':\n",
        "            id_tone = str(i-1) + ',' + str(i) + ',' + str(i+1) # тоже\n",
        "            tone = int(not tone)\n",
        "          else:\n",
        "            id_tone = str(i+1) # тож\n",
        "            tone = int(tone)\n",
        "        except IndexError:\n",
        "          pass\n",
        "        current = str(id_sent) + '\\t' + id_tone + '\\t' + 'Service\\t' + str(tone)\n",
        "        result.add(current)\n",
        "  return(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7fXF_g6S6r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vect_sim(word, vector1, vector2):\n",
        "  sim1 = spatial.distance.cosine(amodel.wv[convert_word(word)], vector1)\n",
        "  sim2 = spatial.distance.cosine(amodel.wv[convert_word(word)], vector2)\n",
        "  return sim1, sim2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPkrsL-AuSDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier2(file, result = set()): \n",
        "  ## можно вместо пустого резалта давать ему резалт из другого классифаера и они будут объединяться\n",
        "  \"\"\"\n",
        "  Например, можно будет сделать так:\n",
        "  Сверху у нас уже есть simple_result первого классификатора на тексте 6668\n",
        "  Можно запустить классификатор два на этом результате\n",
        "  result = classifier2(file, result = simple_result)\n",
        "  Тогда классификатор2 будет добавлять свои штучки в то же множество, и данные не будут повторяться\n",
        "\n",
        "  И вообще потом эти функции можно запускать на куче текстов друг за другом\n",
        "  \"\"\"\n",
        "  sents, food_class_r, service_class_r = get_topics(file, service_topic_vector, food_topic_vector)\n",
        "\n",
        "  for obj in food_class_r:\n",
        "    id_sent = food_class_r[obj]\n",
        "    sent = re.sub ('- ', '', sents[id_sent])\n",
        "    sent_words = [normalize_pm(w.strip())[0] for w in sent.split()]\n",
        "    asp_label = 'Food'\n",
        "    word = obj[0]\n",
        "    p = morph.parse(word)[0]\n",
        "    pos = p.tag.POS\n",
        "    id_word = sent_words.index(word)\n",
        "    #print(sent)\n",
        "\n",
        "    if pos == 'ADVB':\n",
        "      sim_pos, sim_neg = vect_sim(word, pos_vector, neg_vector)\n",
        "      if sim_pos < sim_neg:\n",
        "        label = 1\n",
        "      else: \n",
        "        label = 0\n",
        "      current = str(id_sent + 1) + '\\t' + str(id_word + 1) + '\\t' + str(asp_label) + '\\t' + str(label)\n",
        "      result.add(current)\n",
        "      #print(current, word)\n",
        "      \n",
        "    elif pos == 'ADJF':\n",
        "      try:\n",
        "        target_noun1 = sent_words[id_word+1]\n",
        "        p = morph.parse(target_noun1)[0]\n",
        "        pos1 = p.tag.POS \n",
        "      except IndexError:\n",
        "        pass\n",
        "      try:\n",
        "        target_noun2 = sent_words[id_word-2]\n",
        "        p = morph.parse(target_noun2)[0]\n",
        "        pos2 = p.tag.POS\n",
        "      except IndexError:\n",
        "        pass\n",
        "\n",
        "      if pos1 and pos1 == 'NOUN':\n",
        "        sim_service, sim_food = vect_sim(target_noun1, service_topic_vector, food_topic_vector)\n",
        "        if sim_service < 0.5 or sim_food < 0.5: #не берем совсем неблизкие к фуд и сервис штуки\n",
        "          if sim_service < sim_food:\n",
        "            asp_label = 'Service'\n",
        "          else:\n",
        "            asp_label = 'Food'\n",
        "        else:\n",
        "          asp_label = None\n",
        "        sim_pos, sim_neg = vect_sim(word, pos_vector, neg_vector)\n",
        "        if sim_pos < sim_neg:\n",
        "          label = 1\n",
        "        else: \n",
        "          label = 0\n",
        "      elif pos2 and pos2 == 'NOUN':\n",
        "        sim_service, sim_food = vect_sim(target_noun2, service_topic_vector, food_topic_vector)\n",
        "        if sim_service < 0.5 or sim_food < 0.5: #не берем совсем неблизкие к фуд и сервис штуки\n",
        "          if sim_service < sim_food:\n",
        "            asp_label = 'Service'\n",
        "          else:\n",
        "            asp_label = 'Food'\n",
        "        else:\n",
        "          asp_label = None\n",
        "        sim_pos, sim_neg = vect_sim(word, pos_vector, neg_vector)\n",
        "        if sim_pos < sim_neg:\n",
        "          label = 1\n",
        "        else: \n",
        "          label = 0\n",
        "      else:\n",
        "        label = None\n",
        "        asp_label = None\n",
        "      if abs(sim_pos - sim_neg) < 0.02:\n",
        "        label = None \n",
        "\n",
        "      current = str(id_sent + 1) + '\\t' + str(id_word + 1) + '\\t' + str(asp_label) + '\\t' + str(label)\n",
        "      result.add(current)\n",
        "      #print(current, word)\n",
        "    \n",
        "    if pos == 'NOUN':\n",
        "      #adj = None\n",
        "      pos1 = None\n",
        "      pos2 = None\n",
        "      try:\n",
        "        target_adj1 = sent_words[id_word-1]\n",
        "        p = morph.parse(target_adj1)[0]\n",
        "        pos1 = p.tag.POS\n",
        "        \n",
        "      except IndexError:\n",
        "        pass\n",
        "      try:\n",
        "        target_adj2 = sent_words[id_word+2]\n",
        "        p = morph.parse(target_adj2)[0]\n",
        "        pos2 = p.tag.POS\n",
        "      except IndexError:\n",
        "        pass\n",
        "      if pos1 and pos1 == 'ADJF':\n",
        "        adj = target_adj1\n",
        "        sim_pos, sim_neg = vect_sim(adj, pos_vector, neg_vector)\n",
        "        if sim_pos < sim_neg:\n",
        "          label = 1\n",
        "        else: \n",
        "          label = 0\n",
        "        if sent_words[sent_words.index(adj)-1] == 'не':\n",
        "          if label == 1:\n",
        "            label == 0\n",
        "          elif label == 0:\n",
        "            label = 1\n",
        "          id_word = str(sent_words.index(adj)) + ',' + str(sent_words.index(adj) + 1) #тк в юдпайпе не с нуля\n",
        "        else: \n",
        "          id_word = str(sent_words.index(adj) + 1)\n",
        "\n",
        "      elif pos2 and pos2 == 'ADJF':\n",
        "        adj = target_adj2\n",
        "        sim_pos, sim_neg = vect_sim(adj, pos_vector, neg_vector)\n",
        "        if sim_pos < sim_neg:\n",
        "          label = 1\n",
        "        else: \n",
        "          label = 0\n",
        "        if sent_words[sent_words.index(adj)-1] == 'не':\n",
        "          if label == 1:\n",
        "            label == 0\n",
        "          elif label == 0:\n",
        "            label = 1\n",
        "          id_word = str(sent_words.index(adj)) + ',' + str(sent_words.index(adj) + 1) #тк в юдпайпе не с нуля\n",
        "        else: \n",
        "          id_word = str(sent_words.index(adj) + 1)\n",
        "\n",
        "      else:\n",
        "        label = None\n",
        "      if abs(sim_pos - sim_neg) < 0.02:\n",
        "        label = None \n",
        "      current = str(id_sent + 1) + '\\t' + str(id_word) + '\\t' + str(asp_label) + '\\t' + str(label)\n",
        "      result.add(current)\n",
        "      #print(current, word)\n",
        "\n",
        "  final_result = set()\n",
        "  for i in result:\n",
        "    if \"None\" not in i:\n",
        "      final_result.add(i)\n",
        "\n",
        "  return final_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3UAMiRzEACw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# вот эту функцию можно применять на любом тексте и получать тональный словарь текста в переменной и файлом\n",
        "def final_classifier(file, result = set()):\n",
        "  '''\n",
        "  На вход функции подается текст в формате string\n",
        "  '''\n",
        "  middle_result = classifier1(file, result)\n",
        "  final_result = classifier2(file, middle_result)\n",
        "\n",
        "  new_file = file.split('.')[0] + '_done.txt'\n",
        "  with open(new_file, 'a', encoding = 'utf-8') as w:\n",
        "    for i in final_result:\n",
        "      w.write(i + '\\n')\n",
        "  return final_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHZufQphLQlc",
        "colab_type": "text"
      },
      "source": [
        "Ниже просто всякие проверки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3PW8U0esXgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_file = '/content/drive/My Drive/автобрея/6668.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zkie31Ar6Dx0",
        "colab_type": "code",
        "outputId": "12ba6d87-d943-4a80-ccbf-d7be7c6ab82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "simple_result = classifier1(test_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cannot handle sentence 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96QD8HG5-1IF",
        "colab_type": "code",
        "outputId": "27d360a4-a118-45b8-fa16-29f426b21eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "simple_result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1\\t4\\tFood\\t1',\n",
              " '1\\t4\\tService\\t1',\n",
              " '10\\t3\\tFood\\t1',\n",
              " '10\\t3\\tService\\t1',\n",
              " '11\\t3\\tFood\\t1',\n",
              " '11\\t3\\tService\\t1',\n",
              " '12\\t3\\tFood\\t1',\n",
              " '12\\t6\\tFood\\t1',\n",
              " '15\\t14\\tFood\\t1',\n",
              " '15\\t14\\tService\\t1',\n",
              " '15\\t3\\tFood\\t1',\n",
              " '15\\t4\\tService\\t1',\n",
              " '2\\t3\\tFood\\t0',\n",
              " '2\\t3\\tService\\t0',\n",
              " '2\\t31\\tFood\\t1',\n",
              " '2\\t31\\tService\\t1',\n",
              " '4\\t10\\tFood\\t1',\n",
              " '4\\t9\\tFood\\t1',\n",
              " '4\\t9\\tService\\t1',\n",
              " '5\\t12\\tService\\t1',\n",
              " '6\\t5\\tFood\\t1',\n",
              " '6\\t5\\tService\\t1',\n",
              " '6\\t7\\tService\\t1'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd5RGQ8XT1HT",
        "colab_type": "code",
        "outputId": "6dacdacb-f07f-454a-fc56-1c4a8eb9e76e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "result_6668 = classifier2(test_file, simple_result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR2DSvjTEc5U",
        "colab_type": "code",
        "outputId": "fee09009-97e8-4ef8-e8c9-6bf76bf2dee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(result_6668)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ2F2ct7EUHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxNL29aTFLpP",
        "colab_type": "code",
        "outputId": "18ed8ebd-4207-41fc-99b0-1d94b8e63b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "result_6668_2 = final_classifier(test_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cannot handle sentence 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWZocu_4FXys",
        "colab_type": "code",
        "outputId": "b66abd5d-64c2-4a5b-8f76-9822a31e71a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(result_6668_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}